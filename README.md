<div align="center">

# ğŸŒŸ Pokemon Streaming Analytics

**Ejemplo prÃ¡ctico de arquitectura Producer-Consumer con tecnologÃ­as Big Data**

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-000?style=for-the-badge&logo=apachekafka)](https://kafka.apache.org/)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=for-the-badge&logo=apachespark&logoColor=black)](https://spark.apache.org/)
[![Cassandra](https://img.shields.io/badge/cassandra-%231287B1.svg?style=for-the-badge&logo=apache-cassandra&logoColor=white)](https://cassandra.apache.org/)
[![Grafana](https://img.shields.io/badge/grafana-%23F46800.svg?style=for-the-badge&logo=grafana&logoColor=white)](https://grafana.com/)

*Un pipeline completo de datos en tiempo real utilizando Pokemon como dataset para demostrar conceptos fundamentales de sistemas distribuidos*

**Desarrollado por:** [Augustin Alexandru Besu](https://github.com/augustinbesu)

</div>

---

## ğŸ¯ Objetivo del Proyecto

Este proyecto implementa una **arquitectura de streaming distribuida** completa, demostrando:

- âœ… **PatrÃ³n Producer-Consumer** con Apache Kafka
- âœ… **Stream Processing** en tiempo real con Apache Spark
- âœ… **Almacenamiento NoSQL** escalable con Cassandra
- âœ… **VisualizaciÃ³n en tiempo real** con Grafana
- âœ… **AnÃ¡lisis interactivo** con Jupyter
- âœ… **APIs RESTful** para exposiciÃ³n de datos
- âœ… **ContainerizaciÃ³n completa** con Docker

---

## ğŸ—ï¸ Arquitectura del Sistema

```mermaid
graph TB
    %% DefiniciÃ³n de estilos para los subgrafos
    classDef datasource fill:#e1f5fe,stroke:#039be5,stroke-width:2px
    classDef ingestion fill:#f3e5f5,stroke:#8e24aa,stroke-width:2px
    classDef broker fill:#fff3e0,stroke:#fb8c00,stroke-width:2px
    classDef processing fill:#e8f5e8,stroke:#43a047,stroke-width:2px
    classDef storage fill:#fce4ec,stroke:#e91e63,stroke-width:2px
    classDef api fill:#f1f8e9,stroke:#689f38,stroke-width:2px
    classDef visualization fill:#fff8e1,stroke:#ffa000,stroke-width:2px
    classDef analytics fill:#e3f2fd,stroke:#1976d2,stroke-width:2px

    %% Nodos principales (fuera de los subgrafos)
    A[ğŸ”— PokeAPI]
    B[ğŸ“¡ Pokemon Producer<br/>Python]
    C[ğŸš€ Apache Kafka<br/>Topic: pokemon-data]
    D[âš¡ Apache Spark<br/>Streaming]
    E[ğŸ—„ï¸ Apache Cassandra]
    F[ğŸŒ REST API<br/>Flask]
    G[ğŸ“Š Grafana Dashboard]
    H[ğŸ“ˆ Jupyter Analytics]

    %% Subgrafos (solo para agrupaciÃ³n visual)
    subgraph "Data Source"
        A
    end
    
    subgraph "Data Ingestion"
        B
    end
    
    subgraph "Message Broker"
        C
    end
    
    subgraph "Stream Processing"
        D
    end
    
    subgraph "Storage Layer"
        E
    end
    
    subgraph "API Layer"
        F
    end
    
    subgraph "Visualization"
        G
    end
    
    subgraph "Analytics"
        H
    end

    %% Conexiones
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    F --> H

    %% Aplicar estilos
    class A datasource
    class B ingestion
    class C broker
    class D processing
    class E storage
    class F api
    class G visualization
    class H analytics
```

### ğŸ”§ Componentes del Sistema

| Componente | TecnologÃ­a | FunciÃ³n | Puerto |
|------------|------------|---------|--------|
| **Data Producer** | Python + Requests | Obtiene datos de PokeAPI y envÃ­a a Kafka | - |
| **Message Broker** | Apache Kafka | Cola de mensajes distribuida | 29092 |
| **Stream Processor** | Apache Spark | Procesamiento en tiempo real | 8080 |
| **Database** | Apache Cassandra | Almacenamiento NoSQL escalable | 9042 |
| **REST API** | Flask | ExposiciÃ³n de datos | 5000 |
| **Dashboard** | Grafana | VisualizaciÃ³n en tiempo real | 3000 |
| **Analytics** | Jupyter Lab | AnÃ¡lisis interactivo | 8888 |

---

## ğŸš€ Inicio RÃ¡pido

### ğŸ“‹ Prerrequisitos

- ğŸ³ **Docker & Docker Compose** (v20.10+)
- ğŸ’¾ **8GB RAM mÃ­nimo** disponible
- ğŸ”Œ **Puertos libres**: 3000, 5000, 8080, 8888, 9042, 29092

### âš¡ InstalaciÃ³n en 3 pasos

<details>
<summary>ğŸ“ <strong>1. Clonar el repositorio</strong></summary>

```bash
git clone https://github.com/augustinbesu/Producer_Consumer_Pokemon.git
cd Producer_Consumer_Pokemon
```
</details>

<details>
<summary>ğŸ”§ <strong>2. Desplegar el ecosistema completo</strong></summary>

```bash
make setup
```

**Este comando automÃ¡ticamente:**
- ğŸ—ï¸ Construye todas las imÃ¡genes Docker
- ğŸš€ Levanta todos los servicios
- âš™ï¸ Configura Kafka con topics
- ğŸ—ƒï¸ Inicializa Cassandra con esquemas
- ğŸ”„ Inicia el pipeline de datos

</details>

<details>
<summary>âœ… <strong>3. Verificar el estado</strong></summary>

```bash
make status              # Estado general
make check-cassandra     # Verificar base de datos
make logs               # Ver logs en tiempo real
```
</details>

---

## ğŸŒ Interfaces de Usuario

<div align="center">

| ğŸ–¥ï¸ Servicio | ğŸ”— URL | ğŸ” Credenciales | ğŸ“ DescripciÃ³n |
|-------------|---------|-----------------|-----------------|
| **ğŸ¨ Grafana** | [localhost:3000](http://localhost:3000) | `admin` / `pokemon123` | Dashboard en tiempo real |
| **ğŸ“Š Jupyter** | [localhost:8888](http://localhost:8888) | Token: `pokemon123` | AnÃ¡lisis de datos |
| **ğŸ”Œ REST API** | [localhost:5000](http://localhost:5000) | - | API de datos |
| **âš¡ Spark UI** | [localhost:8080](http://localhost:8080) | - | Monitor de Spark |

</div>

---

## ğŸ“Š Schema de Base de Datos

<details>
<summary>ğŸ—ƒï¸ <strong>Estructura de Cassandra</strong></summary>

### ğŸ“‹ Tabla `raw_pokemon`
```sql
CREATE TABLE raw_pokemon (
    id int PRIMARY KEY,
    name text,
    height int,
    weight int,
    base_experience int,
    types list<text>,
    abilities list<text>,
    stats map<text, int>,
    timestamp timestamp
);
```

### ğŸ“ˆ Tabla `pokemon_stats`
```sql
CREATE TABLE pokemon_stats (
    stat_type text PRIMARY KEY,
    avg_value double,
    max_value int,
    min_value int,
    count_pokemon bigint,
    updated_at timestamp
);
```

### ğŸ·ï¸ Tabla `pokemon_by_type`
```sql
CREATE TABLE pokemon_by_type (
    type text,
    pokemon_id int,
    pokemon_name text,
    base_experience int,
    timestamp timestamp,
    PRIMARY KEY (type, pokemon_id)
);
```

</details>

---

## ğŸ¯ Funcionalidades Principales

### ğŸ“Š Dashboard de Grafana
- ğŸ”¢ **Contador total** de Pokemon procesados
- â° **Timeline** de procesamiento por hora
- ğŸ¥§ **DistribuciÃ³n circular** de tipos de Pokemon
- ğŸ† **Ranking** de Pokemon por experiencia

### ğŸ”¬ Jupyter Analytics
- ğŸ“ˆ **Visualizaciones interactivas** con Plotly
- ğŸ“Š **AnÃ¡lisis estadÃ­stico** por tipos
- ğŸ” **ExploraciÃ³n de datos** en tiempo real
- ğŸ“‹ **Correlaciones** entre atributos

### ğŸ”Œ API REST Endpoints

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| `GET` | `/health` | Estado del servicio |
| `GET` | `/api/total-pokemon` | Total procesados |
| `GET` | `/api/type-distribution` | DistribuciÃ³n por tipos |
| `GET` | `/api/top-pokemon` | Top por experiencia |
| `POST` | `/query` | Endpoint para Grafana |

---

## ğŸ› ï¸ Comandos de GestiÃ³n

<details>
<summary>ğŸ‘ï¸ <strong>Monitoreo</strong></summary>

```bash
make status              # Estado de servicios
make logs               # Logs en tiempo real
make logs-producer      # Logs del productor
make logs-spark         # Logs de Spark
make logs-grafana       # Logs de Grafana
```
</details>

<details>
<summary>ğŸ” <strong>VerificaciÃ³n</strong></summary>

```bash
make check-cassandra    # Datos en Cassandra
make check-kafka       # Topics de Kafka

# Consultas directas
docker exec cassandra cqlsh -e "SELECT COUNT(*) FROM pokemon_data.raw_pokemon;"
docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic pokemon-data --from-beginning
```
</details>

<details>
<summary>ğŸ”„ <strong>GestiÃ³n de Servicios</strong></summary>

```bash
make restart-producer   # Reiniciar productor
make restart-spark      # Reiniciar Spark
make restart-grafana    # Reiniciar Grafana
make clean             # Limpiar todo
make setup             # Reconstruir completo
```
</details>

---

## ğŸ“ˆ Pipeline de Datos

### 1ï¸âƒ£ **Ingesta** 
- **Fuente**: [PokeAPI](https://pokeapi.co/)
- **Frecuencia**: 3-8 segundos (aleatorio)
- **Formato**: JSON estructurado
- **Volumen**: ~100-200 Pokemon/hora

### 2ï¸âƒ£ **Streaming**
- **Broker**: Apache Kafka
- **Topic**: `pokemon-data`
- **Particiones**: 3
- **RetenciÃ³n**: 24 horas

### 3ï¸âƒ£ **Procesamiento**
- **Engine**: Apache Spark Streaming
- **Trigger**: Cada 10-20 segundos
- **Operaciones**: Parseo, limpieza, agregaciones

### 4ï¸âƒ£ **Almacenamiento**
- **BD**: Apache Cassandra
- **Estrategia**: SimpleStrategy
- **ReplicaciÃ³n**: Factor 1

---

## ğŸ§° Stack TecnolÃ³gico

<div align="center">

| CategorÃ­a | TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|-----------|------------|---------|-----------|
| **ğŸ³ Contenedores** | Docker Compose | 3.8 | OrquestaciÃ³n |
| **ğŸ“¨ Streaming** | Apache Kafka | 2.8 | Message Broker |
| **âš¡ Procesamiento** | Apache Spark | 3.3 | Stream Processing |
| **ğŸ—„ï¸ Base de Datos** | Apache Cassandra | 4.0 | NoSQL Storage |
| **ğŸŒ API** | Flask | 2.3 | REST Services |
| **ğŸ“Š VisualizaciÃ³n** | Grafana | 9.0 | Dashboards |
| **ğŸ”¬ Analytics** | Jupyter Lab | 3.6 | Data Science |
| **ğŸ Lenguaje** | Python | 3.9 | Backend |

</div>

---

## ğŸš¨ Troubleshooting

<details>
<summary>âš ï¸ <strong>Problemas Comunes</strong></summary>

### ğŸ”´ Servicios no inician
```bash
docker compose logs <servicio>
docker system df  # Verificar espacio en disco
make clean        # Limpiar recursos
```

### ğŸŸ¡ Cassandra no responde
```bash
# Esperar 1-2 minutos para inicializaciÃ³n completa
docker exec cassandra nodetool status
docker exec cassandra cqlsh -e "DESCRIBE KEYSPACES;"
```

### ğŸŸ  Spark desconectado de Cassandra
```bash
docker exec spark-processor ping cassandra
make restart-spark
docker compose logs spark-processor
```

### ğŸ”µ **Grafana no muestra datos (API 404)**
**SÃ­ntoma:** Los endpoints `/api/total-pokemon` devuelven 404
**Causa:** Docker estÃ¡ ejecutando versiÃ³n anterior del cÃ³digo sin los nuevos endpoints

**SoluciÃ³n:**
```bash
# Reconstruir especÃ­ficamente la API
docker compose stop pokemon-api
docker compose build --no-cache pokemon-api
docker compose up -d pokemon-api

# Verificar que funciona
curl http://localhost:5000/api/total-pokemon
# DeberÃ­a devolver: {"total": X}
```

### ğŸŸ£ Kafka topic no existe
```bash
# Crear topic manualmente si falla kafka-setup.sh
docker exec kafka kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --replication-factor 1 \
    --partitions 3 \
    --topic pokemon-data
```

### ğŸŸ¢ **Script bash no ejecuta (WSL/Linux)**
**SÃ­ntoma:** `./kafka-setup.sh: cannot execute: required file not found`
**Causa:** Archivos creados en Windows con line endings CRLF

**SoluciÃ³n:**
```bash
# OpciÃ³n 1: Usar dos2unix
dos2unix kafka-setup.sh
chmod +x kafka-setup.sh

# OpciÃ³n 2: Recrear archivo
rm kafka-setup.sh
cat > kafka-setup.sh << 'EOF'
#!/bin/bash
echo "Creando topic pokemon-data..."
docker exec kafka kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --replication-factor 1 \
    --partitions 3 \
    --topic pokemon-data
EOF
chmod +x kafka-setup.sh
```

### âš« Producer no conecta a PokeAPI
```bash
# Verificar conectividad
docker exec pokemon-producer ping 8.8.8.8
docker exec pokemon-producer curl https://pokeapi.co/api/v2/pokemon/1
```

</details>

<details>
<summary>ğŸ“‹ <strong>Logs de VerificaciÃ³n</strong></summary>

**âœ… Productor funcionando:**
```
INFO - Pokemon magnemite enviado - Partition: 0, Offset: 5
INFO - Pokemon dragonite enviado - Partition: 0, Offset: 6
```

**âœ… Spark procesando:**
```
INFO - Batch 5: Escribiendo 3 registros a Cassandra
INFO - Batch 5: 3 registros escritos a raw_pokemon
```

**âœ… API funcionando:**
```
INFO - Conectado a Cassandra
INFO:werkzeug:172.18.0.1 - - [GET /api/total-pokemon HTTP/1.1] 200 -
```

**âœ… Cassandra con datos:**
```bash
$ make check-cassandra
 count
-------
    25
```

**âŒ API con imagen antigua:**
```
INFO:werkzeug:172.18.0.1 - - [GET /api/total-pokemon HTTP/1.1] 404 -
```

</details>

<details>
<summary>ğŸ”§ <strong>Comandos de DiagnÃ³stico RÃ¡pido</strong></summary>

```bash
# Pipeline completo
make status                           # Estado general
curl http://localhost:5000/health     # API health check
curl http://localhost:5000/api/total-pokemon  # Endpoint especÃ­fico
make check-cassandra                  # Datos en BD

# Verificar flujo de datos
make logs-producer | grep "enviado"   # Pokemon siendo enviados
make logs-spark | grep "registros"    # Batches procesados
docker exec kafka kafka-console-consumer \
    --bootstrap-server localhost:9092 \
    --topic pokemon-data --max-messages 3  # Mensajes en Kafka
```

</details>

<details>
<summary>ğŸš€ <strong>Reinicio Limpio</strong></summary>

**Si nada funciona, reinicio completo:**
```bash
# Parar todo
docker compose down

# Limpiar imÃ¡genes y volÃºmenes
docker compose down -v
docker system prune -f

# Reconstruir desde cero
make setup

# Esperar 2-3 minutos y verificar
make status
curl http://localhost:5000/api/total-pokemon
```

</details>

---

## ğŸ“Š MÃ©tricas de Rendimiento

<div align="center">

| MÃ©trica | Valor TÃ­pico | DescripciÃ³n |
|---------|--------------|-------------|
| **âš¡ Latencia de ingesta** | < 100ms | Tiempo desde API hasta Kafka |
| **ğŸš€ Throughput Kafka** | 100-1K msg/seg | Capacidad de mensajes |
| **â±ï¸ Latencia Spark** | 10-30 segundos | Procesamiento por batch |
| **ğŸ”Œ API Response** | < 200ms | Tiempo de respuesta |
| **ğŸ“Š ActualizaciÃ³n Grafana** | 5 segundos | Frecuencia de refresh |

</div>

---

## ğŸ”® Posibles Extensiones

- ğŸ”— **Kafka Connect** para conectores automÃ¡ticos
- ğŸŒŠ **Apache Airflow** para orquestaciÃ³n de workflows  
- âš¡ **Redis** para cachÃ© de consultas frecuentes
- ğŸ” **Elasticsearch** para bÃºsquedas textuales
- ğŸ¤– **Machine Learning** para predicciones de Pokemon
- ğŸ”’ **Security** con autenticaciÃ³n y autorizaciÃ³n
- ğŸŒ **Kubernetes** para despliegue en producciÃ³n

---

<div align="center">

## ğŸ“ Fines Educativos

> Este proyecto estÃ¡ diseÃ±ado para **demostrar conceptos de Big Data** y **sistemas distribuidos**. 
> Para entornos de producciÃ³n, considerar configuraciones adicionales de **seguridad**, **monitoreo** y **escalabilidad**.

</div>
