<div align="center">

# ğŸŒŸ Pokemon Streaming Analytics

**Ejemplo prÃ¡ctico de arquitectura Producer-Consumer con tecnologÃ­as Big Data**

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-000?style=for-the-badge&logo=apachekafka)](https://kafka.apache.org/)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=for-the-badge&logo=apachespark&logoColor=black)](https://spark.apache.org/)
[![Cassandra](https://img.shields.io/badge/cassandra-%231287B1.svg?style=for-the-badge&logo=apache-cassandra&logoColor=white)](https://cassandra.apache.org/)
[![Grafana](https://img.shields.io/badge/grafana-%23F46800.svg?style=for-the-badge&logo=grafana&logoColor=white)](https://grafana.com/)

*Un pipeline completo de datos en tiempo real utilizando Pokemon como dataset para demostrar conceptos fundamentales de sistemas distribuidos*

**Desarrollado por:** [Augustin Alexandru Besu](https://github.com/augustinbesu)

</div>

---

## ğŸ¯ Objetivo del Proyecto

Este proyecto implementa una **arquitectura de streaming distribuida** completa, demostrando:

- âœ… **PatrÃ³n Producer-Consumer** con Apache Kafka
- âœ… **Stream Processing** en tiempo real con Apache Spark
- âœ… **Almacenamiento NoSQL** escalable con Cassandra
- âœ… **VisualizaciÃ³n en tiempo real** con Grafana
- âœ… **AnÃ¡lisis interactivo** con Jupyter
- âœ… **APIs RESTful** para exposiciÃ³n de datos
- âœ… **ContainerizaciÃ³n completa** con Docker

---

## ğŸ—ï¸ Arquitectura del Sistema

```mermaid
graph TB
    subgraph "Data Source"
        A[ğŸ”— PokeAPI]
    end
    
    subgraph "Data Ingestion"
        B[ğŸ“¡ Pokemon Producer<br/>Python]
    end
    
    subgraph "Message Broker"
        C[ğŸš€ Apache Kafka<br/>Topic: pokemon-data]
    end
    
    subgraph "Stream Processing"
        D[âš¡ Apache Spark<br/>Streaming]
    end
    
    subgraph "Storage Layer"
        E[ğŸ—„ï¸ Apache Cassandra<br/>NoSQL Database]
    end
    
    subgraph "API Layer"
        F[ğŸŒ REST API<br/>Flask]
    end
    
    subgraph "Visualization"
        G[ğŸ“Š Grafana Dashboard]
        H[ğŸ“ˆ Jupyter Analytics]
    end
    
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    F --> H
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style D fill:#e8f5e8
    style E fill:#fce4ec
    style F fill:#f1f8e9
    style G fill:#fff8e1
    style H fill:#e3f2fd
```

### ğŸ”§ Componentes del Sistema

| Componente | TecnologÃ­a | FunciÃ³n | Puerto |
|------------|------------|---------|--------|
| **Data Producer** | Python + Requests | Obtiene datos de PokeAPI y envÃ­a a Kafka | - |
| **Message Broker** | Apache Kafka | Cola de mensajes distribuida | 29092 |
| **Stream Processor** | Apache Spark | Procesamiento en tiempo real | 8080 |
| **Database** | Apache Cassandra | Almacenamiento NoSQL escalable | 9042 |
| **REST API** | Flask | ExposiciÃ³n de datos | 5000 |
| **Dashboard** | Grafana | VisualizaciÃ³n en tiempo real | 3000 |
| **Analytics** | Jupyter Lab | AnÃ¡lisis interactivo | 8888 |

---

## ğŸš€ Inicio RÃ¡pido

### ğŸ“‹ Prerrequisitos

- ğŸ³ **Docker & Docker Compose** (v20.10+)
- ğŸ’¾ **8GB RAM mÃ­nimo** disponible
- ğŸ”Œ **Puertos libres**: 3000, 5000, 8080, 8888, 9042, 29092

### âš¡ InstalaciÃ³n en 3 pasos

<details>
<summary>ğŸ“ <strong>1. Clonar el repositorio</strong></summary>

```bash
git clone https://github.com/augustinbesu/Producer_Consumer_Pokemon.git
cd Producer_Consumer_Pokemon
```
</details>

<details>
<summary>ğŸ”§ <strong>2. Desplegar el ecosistema completo</strong></summary>

```bash
make setup
```

**Este comando automÃ¡ticamente:**
- ğŸ—ï¸ Construye todas las imÃ¡genes Docker
- ğŸš€ Levanta todos los servicios
- âš™ï¸ Configura Kafka con topics
- ğŸ—ƒï¸ Inicializa Cassandra con esquemas
- ğŸ”„ Inicia el pipeline de datos

</details>

<details>
<summary>âœ… <strong>3. Verificar el estado</strong></summary>

```bash
make status              # Estado general
make check-cassandra     # Verificar base de datos
make logs               # Ver logs en tiempo real
```
</details>

---

## ğŸŒ Interfaces de Usuario

<div align="center">

| ğŸ–¥ï¸ Servicio | ğŸ”— URL | ğŸ” Credenciales | ğŸ“ DescripciÃ³n |
|-------------|---------|-----------------|-----------------|
| **ğŸ¨ Grafana** | [localhost:3000](http://localhost:3000) | `admin` / `pokemon123` | Dashboard en tiempo real |
| **ğŸ“Š Jupyter** | [localhost:8888](http://localhost:8888) | Token: `pokemon123` | AnÃ¡lisis de datos |
| **ğŸ”Œ REST API** | [localhost:5000](http://localhost:5000) | - | API de datos |
| **âš¡ Spark UI** | [localhost:8080](http://localhost:8080) | - | Monitor de Spark |

</div>

---

## ğŸ“Š Schema de Base de Datos

<details>
<summary>ğŸ—ƒï¸ <strong>Estructura de Cassandra</strong></summary>

### ğŸ“‹ Tabla `raw_pokemon`
```sql
CREATE TABLE raw_pokemon (
    id int PRIMARY KEY,
    name text,
    height int,
    weight int,
    base_experience int,
    types list<text>,
    abilities list<text>,
    stats map<text, int>,
    timestamp timestamp
);
```

### ğŸ“ˆ Tabla `pokemon_stats`
```sql
CREATE TABLE pokemon_stats (
    stat_type text PRIMARY KEY,
    avg_value double,
    max_value int,
    min_value int,
    count_pokemon bigint,
    updated_at timestamp
);
```

### ğŸ·ï¸ Tabla `pokemon_by_type`
```sql
CREATE TABLE pokemon_by_type (
    type text,
    pokemon_id int,
    pokemon_name text,
    base_experience int,
    timestamp timestamp,
    PRIMARY KEY (type, pokemon_id)
);
```

</details>

---

## ğŸ¯ Funcionalidades Principales

### ğŸ“Š Dashboard de Grafana
- ğŸ”¢ **Contador total** de Pokemon procesados
- â° **Timeline** de procesamiento por hora
- ğŸ¥§ **DistribuciÃ³n circular** de tipos de Pokemon
- ğŸ† **Ranking** de Pokemon por experiencia

### ğŸ”¬ Jupyter Analytics
- ğŸ“ˆ **Visualizaciones interactivas** con Plotly
- ğŸ“Š **AnÃ¡lisis estadÃ­stico** por tipos
- ğŸ” **ExploraciÃ³n de datos** en tiempo real
- ğŸ“‹ **Correlaciones** entre atributos

### ğŸ”Œ API REST Endpoints

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| `GET` | `/health` | Estado del servicio |
| `GET` | `/api/total-pokemon` | Total procesados |
| `GET` | `/api/type-distribution` | DistribuciÃ³n por tipos |
| `GET` | `/api/top-pokemon` | Top por experiencia |
| `POST` | `/query` | Endpoint para Grafana |

---

## ğŸ› ï¸ Comandos de GestiÃ³n

<details>
<summary>ğŸ‘ï¸ <strong>Monitoreo</strong></summary>

```bash
make status              # Estado de servicios
make logs               # Logs en tiempo real
make logs-producer      # Logs del productor
make logs-spark         # Logs de Spark
make logs-grafana       # Logs de Grafana
```
</details>

<details>
<summary>ğŸ” <strong>VerificaciÃ³n</strong></summary>

```bash
make check-cassandra    # Datos en Cassandra
make check-kafka       # Topics de Kafka

# Consultas directas
docker exec cassandra cqlsh -e "SELECT COUNT(*) FROM pokemon_data.raw_pokemon;"
docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic pokemon-data --from-beginning
```
</details>

<details>
<summary>ğŸ”„ <strong>GestiÃ³n de Servicios</strong></summary>

```bash
make restart-producer   # Reiniciar productor
make restart-spark      # Reiniciar Spark
make restart-grafana    # Reiniciar Grafana
make clean             # Limpiar todo
make setup             # Reconstruir completo
```
</details>

---

## ğŸ“ˆ Pipeline de Datos

### 1ï¸âƒ£ **Ingesta** 
- **Fuente**: [PokeAPI](https://pokeapi.co/)
- **Frecuencia**: 3-8 segundos (aleatorio)
- **Formato**: JSON estructurado
- **Volumen**: ~100-200 Pokemon/hora

### 2ï¸âƒ£ **Streaming**
- **Broker**: Apache Kafka
- **Topic**: `pokemon-data`
- **Particiones**: 3
- **RetenciÃ³n**: 24 horas

### 3ï¸âƒ£ **Procesamiento**
- **Engine**: Apache Spark Streaming
- **Trigger**: Cada 10-20 segundos
- **Operaciones**: Parseo, limpieza, agregaciones

### 4ï¸âƒ£ **Almacenamiento**
- **BD**: Apache Cassandra
- **Estrategia**: SimpleStrategy
- **ReplicaciÃ³n**: Factor 1

---

## ğŸ§° Stack TecnolÃ³gico

<div align="center">

| CategorÃ­a | TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|-----------|------------|---------|-----------|
| **ğŸ³ Contenedores** | Docker Compose | 3.8 | OrquestaciÃ³n |
| **ğŸ“¨ Streaming** | Apache Kafka | 2.8 | Message Broker |
| **âš¡ Procesamiento** | Apache Spark | 3.3 | Stream Processing |
| **ğŸ—„ï¸ Base de Datos** | Apache Cassandra | 4.0 | NoSQL Storage |
| **ğŸŒ API** | Flask | 2.3 | REST Services |
| **ğŸ“Š VisualizaciÃ³n** | Grafana | 9.0 | Dashboards |
| **ğŸ”¬ Analytics** | Jupyter Lab | 3.6 | Data Science |
| **ğŸ Lenguaje** | Python | 3.9 | Backend |

</div>

---

## ğŸš¨ Troubleshooting

<details>
<summary>âš ï¸ <strong>Problemas Comunes</strong></summary>

### ğŸ”´ Servicios no inician
```bash
docker compose logs <servicio>
docker system df  # Verificar espacio
```

### ğŸŸ¡ Cassandra no responde
```bash
# Esperar 1-2 minutos para inicializaciÃ³n
docker exec cassandra nodetool status
```

### ğŸŸ  Spark desconectado
```bash
docker exec spark-processor ping cassandra
make restart-spark
```

### ğŸ”µ Grafana sin datos
```bash
curl http://localhost:5000/api/total-pokemon
# Verificar datasource en Grafana UI
```

</details>

<details>
<summary>ğŸ“‹ <strong>Logs de VerificaciÃ³n</strong></summary>

**âœ… Productor funcionando:**
```
INFO - Obtenido Pokemon: charizard (id: 6)
INFO - Enviado a Kafka: pokemon-data
```

**âœ… Spark procesando:**
```
INFO - Batch 5: Escribiendo 3 registros a Cassandra
INFO - Batch 5: 3 registros escritos a raw_pokemon
```

**âœ… API funcionando:**
```
INFO - Conectado a Cassandra
INFO - get_type_distribution devolviÃ³ 5 tipos
```

</details>

---

## ğŸ“Š MÃ©tricas de Rendimiento

<div align="center">

| MÃ©trica | Valor TÃ­pico | DescripciÃ³n |
|---------|--------------|-------------|
| **âš¡ Latencia de ingesta** | < 100ms | Tiempo desde API hasta Kafka |
| **ğŸš€ Throughput Kafka** | 100-1K msg/seg | Capacidad de mensajes |
| **â±ï¸ Latencia Spark** | 10-30 segundos | Procesamiento por batch |
| **ğŸ”Œ API Response** | < 200ms | Tiempo de respuesta |
| **ğŸ“Š ActualizaciÃ³n Grafana** | 5 segundos | Frecuencia de refresh |

</div>

---

## ğŸ”® Posibles Extensiones

- ğŸ”— **Kafka Connect** para conectores automÃ¡ticos
- ğŸŒŠ **Apache Airflow** para orquestaciÃ³n de workflows  
- âš¡ **Redis** para cachÃ© de consultas frecuentes
- ğŸ” **Elasticsearch** para bÃºsquedas textuales
- ğŸ¤– **Machine Learning** para predicciones de Pokemon
- ğŸ”’ **Security** con autenticaciÃ³n y autorizaciÃ³n
- ğŸŒ **Kubernetes** para despliegue en producciÃ³n

---

<div align="center">

## ğŸ“ Fines Educativos

> Este proyecto estÃ¡ diseÃ±ado para **demostrar conceptos de Big Data** y **sistemas distribuidos**. 
> Para entornos de producciÃ³n, considerar configuraciones adicionales de **seguridad**, **monitoreo** y **escalabilidad**.

</div>
